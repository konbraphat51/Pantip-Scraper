{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get texts from link got from 01\n",
    "\n",
    "Edit \"id\" ,\"devide\" and \"drivers_n\"\n",
    "\n",
    "Data format : (time)(devide)(text content)\n",
    "Default:(time)@@@(text content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import chromedriver_binary\n",
    "from concurrent import futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = \"Mitsubishi\"\n",
    "\n",
    "link_file = \"Link/PantipLink_%s.txt\"%id\n",
    "text_file = \"TextData/PantipTextData_%s.txt\"%id\n",
    "\n",
    "devide = \"@@@\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will use several browsers in the same time for speed.\n",
    "Thus, this will take CPU resource.\n",
    "Watch your Task Manager and adjust \"drivers_n\" where CPU won't be occupied 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_n = 7   #Adjust!\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "#Open Several drivers\n",
    "drivers = []\n",
    "for _ in range(drivers_n):\n",
    "    drivers.append(webdriver.Chrome(options=chrome_options))\n",
    "\n",
    "drivers_used = [False for _ in range(drivers_n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url):\n",
    "    global scraped, scrape_max, drivers_n, drivers_used, drivers, f\n",
    "\n",
    "    #find open driver\n",
    "    for index in range(drivers_n):\n",
    "        if drivers_used[index] == False:\n",
    "            using_index = index\n",
    "            drivers_used[index] = True\n",
    "            driver = drivers[index]\n",
    "            break\n",
    "\n",
    "    #Open Page\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    " \n",
    "    posts = soup.find_all(class_=\"display-post-status-leftside\")\n",
    " \n",
    "    #Scrape texts\n",
    "    for post in posts:\n",
    "\n",
    "        el = post.find(\"div\", class_=\"display-post-story\")\n",
    "    \n",
    "        #get post time\n",
    "        if post.find(\"abbr\") == None:\n",
    "            continue\n",
    "        time = post.find(\"abbr\").get(\"data-utime\")\n",
    "        \n",
    "        #erace edit history\n",
    "        for history in el.find_all(\"div\", class_ = \"edit-history\"):\n",
    "            history.decompose()\n",
    "\n",
    "        #make it clean\n",
    "        texts = el.text.replace(\"\\t\", \" \").replace(\"\\n\", \" \").split(\" \")\n",
    "        text = \"\".join(texts)\n",
    "       \n",
    "        #save\n",
    "        try:\n",
    "            f.write(time + devide + text + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(text)\n",
    "    \n",
    "    drivers_used[using_index] = False\n",
    "\n",
    "    #show progress\n",
    "    scraped += 1\n",
    "    if (scraped / scrape_max) % 0.05  < 0.005:\n",
    "        print((scraped/scrape_max)*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00018772292096865028\n",
      "0.050122019898629626\n",
      "0.1000563168762906\n",
      "0.1501783367749202\n",
      "0.2001126337525812\n",
      "0.25004693073024215\n",
      "0.3001689506288718\n",
      "0.3501032476065328\n",
      "0.4000375445841937\n",
      "0.45015956448282335\n",
      "0.5000938614604843\n",
      "0.5500281584381453\n",
      "0.600150178336775\n",
      "0.6500844753144359\n",
      "0.7000187722920969\n",
      "0.7501407921907265\n",
      "0.8000750891683874\n",
      "0.8500093861460485\n",
      "0.8501971090670171\n",
      "0.900131406044678\n",
      "0.9500657030223391\n"
     ]
    }
   ],
   "source": [
    "links_f = open(link_file, \"r\")\n",
    "\n",
    "links = links_f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "links_f.close()\n",
    "\n",
    "f = open(text_file, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "#scrape texts in the same time\n",
    "scraped = 0\n",
    "scrape_max = len(links)\n",
    "future_list = []\n",
    "with futures.ThreadPoolExecutor(max_workers=drivers_n) as executor:\n",
    "    for link in links:\n",
    "        future = executor.submit(scrape, url=link)\n",
    "        future_list.append(future)\n",
    "    _ = futures.as_completed(fs=future_list)\n",
    " \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ccdf6fa2fe9851812a686c56b7994b1ea39ca8a45af3f74f45e3d9b9ebb2838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
